{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all the imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data and drop the NA values.\n",
    "data_path = \"input_data/NY-House-Dataset.csv\"\n",
    "all_data = pd.read_csv(data_path).dropna().reset_index()\n",
    "\n",
    "# Get rid of the specific TYPEs that are not needed in the data\n",
    "for type in [\"Foreclosure\", \"Pending\", \"Coming Soon\", \"Land for sale\", \"Contingent\", \"For sale\"]:\n",
    "    all_data.drop(all_data[all_data['TYPE'] == type].index, inplace=True)\n",
    "\n",
    "# Rename the types and save them to a separate column. Do the same as above for the brokertitle too\n",
    "type_save = [tpe[:-9].replace(\" \", \"-\") for tpe in all_data[\"TYPE\"].to_numpy().tolist()]\n",
    "all_data[\"Type\"] = type_save\n",
    "\n",
    "all_data = all_data.loc[all_data[\"PRICE\"].between(10000, 1000000000), :]\n",
    "all_data = all_data.drop(columns=[\"ADMINISTRATIVE_AREA_LEVEL_2\", \"MAIN_ADDRESS\", \"ADDRESS\", \n",
    "                                  \"FORMATTED_ADDRESS\", \"LONGITUDE\", \"LATITUDE\", \"LONG_NAME\", \"BROKERTITLE\", \"TYPE\", \"LOCALITY\", \"SUBLOCALITY\", \"STATE\", \"STREET_NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row 1: min, row 2: median, row 3: mean, row 4: max, row 5: standard deviation\n",
    "stat_cols = [\"PRICE\", \"BEDS\", \"BATH\", \"PROPERTYSQFT\"]\n",
    "stat_rows = [\"Min\", \"Median\", \"Mean\", \"Max\", \"Std.\"]\n",
    "stats_df = pd.DataFrame(np.arange(20).reshape(5, 4), index=stat_rows, columns=stat_cols)\n",
    "\n",
    "# Loop over colums and get fill the stats\n",
    "for col in stat_cols:\n",
    "\n",
    "    # Get the column and column data\n",
    "    col_data = all_data[col].to_numpy()\n",
    "\n",
    "    # Get all stats\n",
    "    stats_dict = {}\n",
    "    stats_dict[\"Min\"], stats_dict[\"Max\"] = col_data.min(), col_data.max()\n",
    "    stats_dict[\"Median\"], stats_dict[\"Mean\"], stats_dict[\"Std.\"] = round(np.median(col_data), 2), round(np.average(col_data), 2),  round(np.std(col_data), 2)\n",
    "\n",
    "    # Add the data\n",
    "    for row in stat_rows:\n",
    "        stats_df.loc[row, col] = stats_dict[row]\n",
    "\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_idx(unique_attribute_vals: list):\n",
    "\n",
    "    # Initialize the variables\n",
    "    value_to_idx = {}\n",
    "    idx_to_value = {}\n",
    "    unique_int = 100\n",
    "\n",
    "    # Loop through to map the values\n",
    "    for value in unique_attribute_vals:\n",
    "        value_to_idx[value] = unique_int\n",
    "        idx_to_value[unique_int] = value\n",
    "        unique_int = unique_int + 0.001\n",
    "\n",
    "    # Return the two dictionaries\n",
    "    return (value_to_idx, idx_to_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE-HOT ENCODE\n",
    "# https://stackabuse.com/one-hot-encoding-in-python-with-pandas-and-scikit-learn/\n",
    "def one_hot(dataframe, col, pre):\n",
    "  encoded = pd.get_dummies(dataframe[col], prefix=pre)\n",
    "  for column in encoded:\n",
    "    encoded = encoded.rename(columns={column: col + \"_\" + column})\n",
    "  encoded['index'] = dataframe['index']\n",
    "  return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "all_data[\"Type\"] = label_encoder.fit_transform(all_data[\"Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding only the Type.\n",
    "# encoded = one_hot(all_data, \"Type\", 'is')\n",
    "# all_data = pd.merge(all_data, encoded, on=[\"index\"])\n",
    "# all_data = all_data.drop(columns=[\"Type\", \"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.drop(columns=[\"index\"])\n",
    "all_data.to_csv(\"input_data/model_ready_data.csv\", index=False)\n",
    "all_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
